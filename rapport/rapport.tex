\documentclass[oneside,13pt,a4paper]{report}

% Chargement d'extensions
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage[top=3cm, bottom=3cm, left=3cm, right=3cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}

% Bout de code
\usepackage{listings}
\usepackage{color}

% arabe
\usepackage{arabtex}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  firstnumber=0,                   % start line enumeration with line 1000
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=C++,                    % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
}

% Commande pour notation 'NB :' (nota bene)
\newcommand\nb[1][0.3]{N\kern-#1emB : }

% csquotes va utiliser la langue définie dans babel
\usepackage[babel=true]{csquotes}

% pour afficher Schéma au lieu de figure dans les legende des images
\addto\captionsfrench{\def\figurename{Schéma}}

% Informations le titre, le(s) auteur(s), la date
\title{Claims checking}
\author{
    Belkassim BOUZIDI \and
    Chakib ELHOUITI \and
    Massili KEZZOUL \and
    Abdelkader Nedjari \and
    Ramzi ZEROUAL
}
\date{\today}


\begin{document}
%\maketitle
\begin{titlepage}
	\centering
	{\scshape\LARGE Universite de Montpellier\par}
	{\scshape\Large Rapport de projet\par}
	\vspace{1.5cm}
	{\huge\bfseries Claims checking\par}
	\vspace{2cm}
	{\Large\itshape
		Belkassim BOUZIDI \\
		Chakib ELHOUITI \\
		Massili KEZZOUL \\
		Abdelkader Nedjari \\
		Ramzi ZEROUAL \\
		\par}

	\vspace{1.5cm}

	{\Large\itshape
		Encadrante :\par
		M\up{r} Konstantin \textsc{Todorov}
		\par}

	\vspace{2cm}

	\begin{figure}[h]
		\begin{minipage}[c]{.46\linewidth}
			\centering
			\includegraphics[width=1\textwidth]{img/univ-montpellier.png}
		\end{minipage}
		\hfill%
		\begin{minipage}[c]{.46\linewidth}
			\centering
			\includegraphics[width=1\textwidth]{img/fds.png}
		\end{minipage}
	\end{figure}

	\par\vspace{1cm}

	\vfill

	% Bottom of the page
	{\large \today\par}
\end{titlepage}




% ------------------------------------- %
% Introduction
% ------------------------------------- %

\parskip=5pt
\chapter*{Remerciements}
\vspace{\stretch{1}}
\begin{center}

	Tout d'abord nous souhaitons adresser nos remerciements au corps professoral et administratif de la faculté des sciences de Montpellier qui déploient des efforts pour assurer à leurs étudiants une formation actualisée.

	En second lieu, nous tenons à remercier notre encadrante M\up{me}  pour ses précieux conseils et son aide durant toute la période du travail.

	Nos vifs remerciements vont également aux membres du jury pour l’intérêt qu’ils ont porté à notre projet en acceptant d’examiner notre travail.

	Nous remercions M\up{r} Yahia Zeroual pour sa relecture attentive de ce rapport.

\end{center}
\vspace{\stretch{1}}

\parskip=0pt
\tableofcontents

% Espacement entre les paragraphes
\parskip=5pt
% ------------------------------------- %
% Organisation
% ------------------------------------- %

\chapter{Organisation du projet}
\section{Méthodes d’organisation}

Afin de mener à bien le développement du projet, nous avons décidé de travailler un maximum de temps ensemble et de manière très régulière. Nous nous sommes réunis trois à quatre fois par semaine, en vue de faire le point sur l'avancement du projet et de définir les objectifs restant à atteindre.

Ainsi, selon l'état de progression de la conception du moteur de requêtes, nous réalisâmes les tâches en retard durant le week-end pour ne pas cumuler de retard et respecter l'intégralité du cahier des charges.

Toutes les semaines, nous nous sommes réunis avec notre encadrant , M\up{r} Konstantin \textsc{Todorov} Lors de ces réunions , des mises au point relatives au projet, nous furent prodiguées, cela nous a permis de bénéficier de précieux conseils.

\section{Decoupage du projet}

Nous avons découpé la réalisation du projet en trois grandes phases.

\subsection{Phase de modélisation}

Durant cette étape, nous nous sommes réunis pour définir les fonctionnalités demandées par le projet. Notamment séparer les fonctionnalités importantes de celle moins importantes. Nous avons également choisi les outils de travail collaboratifs et les principales technologies utilisées, ainsi qu’une première modélisation du projet.

\subsection{Phase de développement}

Durant cette phase, nous avons commencé à implémenter les différentes fonctionnalités que nous avons modélisées lors de l'étape précédente, toute en améliorant la modélisation au fur et à mesure de l'avancement de notre projet. Nous avons notamment réalisé des tests pour les différents modules afin de s'assurer de leur bon fonctionnement.

\subsection{Finalisation du projet}

Cette étape a consisté en la réalisation des tests finaux afin de s'assurer que les défferents scripts fonctionnent en toute circonstance et éventuellement corriger les bogues qui peuvent apparaitre.

\section{Outils de collaboration}

Afin de s'organiser, nous avons décidé d'utiliser Git au travers du serveur GitLab hébergé par le service informatique de la faculté. En effet le logiciel libre Git a facilité grandement la collaboration entre nous. Le serveur GitLab quant à lui est fourni gratuitement par le service informatique de la faculté.

En ce qui concerne la rédaction de ce rapport, nous avons utilisé \LaTeX, système de composition de documents créé par Leslie Lamport, pour faciliter la rédaction à plusieurs.

\begin{figure}[h]
	\begin{minipage}[c]{.46\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{img/gitlab.png}
		\caption{Logo du GitLab}
	\end{minipage}
	\hfill%
	\begin{minipage}[c]{.46\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{img/latex.png}
		\caption{Logo de Latex}
	\end{minipage}
\end{figure}



\chapter{Introduction au sujet}

\section{Fact-checking}

\subsection{Présentation du principe de fact-checking}

Le fact-checking ou le vérification des faits, est une technique consistant d'une part à vérifier la véracité des faits et l'exactitude des chiffres présentés dans les médias et les différents réseaux sociaux et les blogues etc... .
Cette notion est apparue aux États-Unis dans les années 1990. Mise en pratique par des journalistes d'investigation dans le cadre de leur profession, la méthode s'est démocratisée grâce à des logiciels aidant les particuliers à vérifier les faits.

L'entrée officielle du fact-checking en France date de 1995, quand est créée l'association Acrimed, qui se présente comme « l'observatoire des médias ».

En vue de la prolifération très rapide des informations, il devient de plus en plus important de s'assurer de la véracité des informations qui se trouvent partout sur Internet et autres médias, tant du point de vue de la société que de celui de la recherche. De nombreuses approches récentes dans diverses communautés scientifiques portent sur des problèmes tels que la vérification des faits, la détection de la pertinence ou de point de vue des documents par rapport à des revendications particulières.

\subsection{Présentation de ClaimsKG}

% [1] tsema faut mettre des liens

Le LIRMM[1] en collaboration avec 2 équipes allemandes (L3S Hannover et l’institut de sciences sociologiques GESIS à Cologne), a construit et mise à disposition la base de connaissance ClaimsKG[1] qui recueillit les informations et méta-données provenant d’un grand nombre de sites journalistiques internationaux de fact checking, tels que Politifact[1] ou Snopes[1]. ClaimsKG est un graphe de connaissances d’assertions annotées et liées qui facilite la création de requêtes structurées sur les assertions, leurs valeurs de vérité (True, Mostly False, etc...), leurs auteurs, date de publication, etc. ClaimsKG est généré par un pipeline entièrement automatisé qui collecte des assertions et des métadonnées à partir des sites de fact-checking, transforme les données en graphes de connaissances selon un modèle établis, et annote les assertions avec des entités DBpedia (Wikipedia). La base actuelle comprend plus de 32,000 assertions publiées depuis 1996 et est mis à jour régulièrement.

\subsection{Travail à réaliser}

Le sujet du TER consiste en l’enrichissement de cette base de connaissances avec des nouvelles données provenant des sites web suivants :

\begin{itemize}
	%"فتبينوا" arabe non pris en charge ?????
	\item[Fatabyyano[1]] Jordani, en Arabe, Fatabyyano (veut dire "Alors montrez-le" en arabe) est la première et la seule plateforme arabe certifiée par l'IFCN [1];
	\item[Vishvas.news[1]] Un site Internet de vérification des faits multilingue (en hindi, anglais ...) qui s'engage à combattre la désinformation et les informations erronées.
\end{itemize}

Le but du TER sera d’identifier les assertions individuelles dans chaque histoire, ainsi que leur label de véracité et par la suite identifier les relations entre les assertions dans chaque histoire, ainsi que les relations entre ces histoires. Les données produites par ce projet seront intégrées à la base de connaissance ClaimsKG.

La principale difficulté qu'on s'attend à rencontrer est la gestion des différentes langues proposée par ces sites web. Notamment dans l'identification des différentes relations entre les assertions. En effet afin de reconnaitre les différents mots-clés du sujet traité par les articles, on utilise habituellement TAGME. un puissant outil de reconnaissance d'entités nommées dans un texte. Les langues utilisées par ces sites web ne sont pas prises en charge par TAGME. Il s'agit donc de trouver une alternative afin de reconnaitre ses différentes assertions. Ce problème ainsi que sa résolution sera détaillé plus tard dans ce rapport.

\section{Technologies utilisées}

Nous avons implémenter l'application en Python[1]. Choix qui s'impose de lui même car couplé à la bibliothèque BeautifulSoup[1] il devient très facile de faire du web Scraping[1].

En ce qui concerne la traduction nous avons choisi d'utiliser Yandex Translator[1]. En effet en vu de la taille des données à traduire nous avons pas pu utiliser l'api de traduction de Google puisque cette dernière devient payante à partir d'un certain nombre de caractères.

En fin, la reconnaissance des différents entitées concerné est faite grace à l'outil TAGME[1] a travers son API python[1].

\vspace{2cm}
\begin{figure}[h]
	\begin{minipage}[c]{.30\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{img/python.jpg}
		\caption{Logo de Python}
	\end{minipage}
	\hfill%
	\begin{minipage}[c]{.30\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{img/bs.png}
		\caption{Logo de BeautifulSoup}
	\end{minipage}
	\hfill%
	\begin{minipage}[c]{.30\linewidth}
		\centering
		\includegraphics[width=1\textwidth]{img/yandex.png}
		\caption{Logo de Yandex}
	\end{minipage}
\end{figure}

\chapter{Conception et implementation du projet}

\section{Conception et Modélisation}
Lors de cette première phase, le plus important a été de comprendre et s'imprégner du code déjà mis en place et mis à notre disposition (Claimskg), comprendre les outils utilisés ainsi que la structure déjà établie.

Comme le projet est d'une envergure immense bien comprendre la structure était primordiale afin de respecter un maximum les outils utilisés, nous avons premièrement analysé les classes principales comme celle de " Claim.py ", puis comprendre comment l'exécution de l'extraction ce fessait avec "init.py " . nous avons ensuite analysé les différents scripts d'extraction de sites de fact cheking.
De ce que nous avons compris du projet il fallait écrire une class qui représente notre site web, puis écrire des méthodes d'extraction (extraction du titre, extraction de la claim ... etc. ) sur une page que nous appliquerons sur tout le site via un script python, chaque méthode représente une colonne du fichier csv final où tous les éléments extraits sont stockés, tous les résultats de chaque méthode sont regroupés dans une méthode qui les regroupent dans la classe principale "Claim.py" et c'est sur celle-ci que le script " init.py " est appliqué.

L'étape suivante était de trouver un site web respectant les critères de fact cheking ainsi que les critères (une véracité, une claim écrite, un auteur, des tags ... etc) du projet initial (Claimskg), pour apporter un maximum de diversité ainsi que notre contribution personnelle spécifique nous avons décidé avec l'accord de notre encadrant d'extraire les données d'un site d'une langue différente pas encore présente dans le projet, comme tous les étudiants présents dans ce projet ont une connaissance de la langue arabe il a été logique de commencer par cette langue, le seul site officiel de fact cheking en arabe est https://fatabyyano.net/ nous avons donc analysé la structure du site web puis commencé son l'implementation, l'étape d'après fut de trouver comment faire une "named entity recognition" sur les mêmes principes que celle déjà présenté ( TagMe qui renvoi vers des liens wikipedia).

Le second site web sur lequel nous avons travaillé est https://www.vishvasnews.com/, 11 langues différentes sont présentent sur ce site : L'anglais, Hindi, Pendjabi, Ourdou, Bengali, Tamoul, Malayalam, Goudjerati, Télougou, Marathi et L'odia , nous avons analysé la structure du site puis extrait ses données.

\section{Implémentation}

\chapter{Analyse des résultats}

\section{résultats}
\section{Problèmes rencotrés}

\chapter{Bilan et conclusions}

\chapter{Bibliographie et annexes}



\end{document}
